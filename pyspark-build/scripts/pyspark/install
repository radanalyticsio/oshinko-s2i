#!/bin/sh

set -e

SCRIPT_DIR=$(dirname $0)
ADDED_DIR=${SCRIPT_DIR}/added
ARTIFACTS_DIR=/tmp/artifacts

fullname=$(find $ARTIFACTS_DIR -name spark-[0-9.]*-bin-hadoop[0-9.]*\.tgz)
bash -x $SCRIPT_DIR/check_for_download $fullname
cp $fullname /opt

pushd /opt
tar -zxf $(basename $fullname)
ln -s $(basename $fullname .tgz) spark
rm $(basename $fullname)
popd

set +e
pip show numpy
res=$?
set -e
if [ "$res" -ne 0 ]
then
    if [ -f /opt/app-root/etc/scl_enable ]
    then
        source /opt/app-root/etc/scl_enable && pip install numpy
    else
        pip install numpy
    fi
fi

mkdir -p /usr/libexec/s2i
cp -r $ADDED_DIR/s2i/* /usr/libexec/s2i
cp $ADDED_DIR/spark-conf/* /opt/spark/conf/
chown -R 185:0 -R $APP_ROOT && chmod a+rwX -R $APP_ROOT
chown -R 185:0 /opt/spark/conf && chmod g+rw -R /opt/spark/conf
