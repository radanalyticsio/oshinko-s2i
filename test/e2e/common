#!/bin/bash
S2I_TEST_INTEGRATED_REGISTRY=${S2I_TEST_INTEGRATED_REGISTRY:-}

if [ -z "$S2I_TEST_IMAGE_PYSPARK" ]; then
    if [ -n "$S2I_TEST_IMAGE_PREFIX" ]; then
	S2I_TEST_IMAGE_PYSPARK=$S2I_TEST_IMAGE_PREFIX-pyspark
    else
	S2I_TEST_IMAGE_PYSPARK=radanalytics-pyspark
    fi
fi

if [ -z "$S2I_TEST_IMAGE_JAVA" ]; then
    if [ -n "$S2I_TEST_IMAGE_PREFIX" ]; then
	S2I_TEST_IMAGE_JAVA=$S2I_TEST_IMAGE_PREFIX-java
    else
	S2I_TEST_IMAGE_JAVA=radanalytics-java-spark
    fi
fi

if [ -z "$S2I_TEST_IMAGE_SCALA" ]; then
    if [ -n "$S2I_TEST_IMAGE_PREFIX" ]; then
	S2I_TEST_IMAGE_SCALA=$S2I_TEST_IMAGE_PREFIX-scala
    else
	S2I_TEST_IMAGE_SCALA=radanalytics-scala-spark
    fi
fi


S2I_TEST_SPARK_IMAGE=${S2I_TEST_SPARK_IMAGE:-docker.io/radanalyticsio/openshift-spark}

S2I_TEST_WORKERS=${S2I_TEST_WORKERS:-1}

PROJECT=$(oc project -q)
MY_SCRIPT=`basename "$0"`

# RESOURCE_DIR will be the directory containing this file
RESOURCE_DIR=$(readlink -f `dirname "${BASH_SOURCE[0]}"`)/resources

# We count on this file being somewhere below oshinko-s2i, and
# the location of hack/lib under oshinko-s2i
source $(readlink -f `dirname "${BASH_SOURCE[0]}"` | grep -o '.*/oshinko-s2i')/hack/lib/init.sh

function print_test_env {
    if [ -n "$S2I_TEST_INTEGRATED_REGISTRY" ]; then
        echo Using integrated registry $S2I_TEST_INTEGRATED_REGISTRY
    else
        echo Not using integrated registry
    fi
    echo Using local s2i pyspark image $S2I_TEST_IMAGE_PYSPARK
    echo Using local s2i java image $S2I_TEST_IMAGE_JAVA
    echo Using local s2i scala image $S2I_TEST_IMAGE_SCALA
    echo Using spark image $S2I_TEST_SPARK_IMAGE
    echo Using $S2I_TEST_WORKERS workers
}

function set_app_exit {
    DO_EXIT="true"
}

function clear_app_exit() {
    DO_EXIT="false"
}

function set_long_running {
    DEL_CLUSTER="false"
}

function set_ephemeral() {
    DEL_CLUSTER="true"
}

function set_spark_sleep() {
    SLEEP=300
}

function clear_spark_sleep() {
    SLEEP=0
}

function set_test_mode() {
    # we want the signal handler to delay so that we can read the pod logs after the pod is deleted   
    DO_TEST="true"
}

function clear_test_mode() {
    DO_TEST="false"
}

function clear_cluster_name() {
    GEN_CLUSTER_NAME=""
}

function init_config_map() {
    set +e
    oc delete configmap clusterconfig masterconfig workerconfig &>/dev/null
    set -e
    oc create configmap masterconfig --from-file=$RESOURCE_DIR/masterconfig &>/dev/null
    oc create configmap workerconfig --from-file=$RESOURCE_DIR/workerconfig &>/dev/null
    oc create configmap clusterconfig --from-literal=workercount=$WORKER_COUNT \
                                      --from-literal=sparkimage=$S2I_TEST_SPARK_IMAGE \
                                      --from-literal=sparkmasterconfig=masterconfig \
                                      --from-literal=sparkworkerconfig=workerconfig &>/dev/null
}

function set_worker_count() {
    if [ "${WORKER_COUNT:-0}" -ne "$1" ]; then
        WORKER_COUNT=$1
        init_config_map
    fi
}

function set_defaults() {
    set_ephemeral
    set_spark_sleep
    clear_app_exit
    clear_test_mode
    clear_cluster_name
}

function run_app() {
    # Launch the app using the service account and create a cluster
    set +e
    SUFFIX=$(cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 4 | head -n 1)
    set -e
    APP_NAME=app-$SUFFIX
    if [ "$#" -ne 1 ]; then
	echo run_app takes 1 parameter, true or false for named or unnamed cluster
	return 1
    fi
    if [ "$1" != true ]; then
        os::cmd::expect_success 'oc new-app --file="$RESOURCE_DIR"/pysparkdc.json -p IMAGE=play -p APPLICATION_NAME="$APP_NAME" -p APP_EXIT="$DO_EXIT" -p APP_ARGS="$SLEEP" -p OSHINKO_DEL_CLUSTER="$DEL_CLUSTER" -p TEST_MODE="$DO_TEST" -p OSHINKO_NAMED_CONFIG=clusterconfig'
        os::cmd::try_until_not_text 'oc get rc "$APP_NAME"-1 --template="{{index .metadata.labels \"uses-oshinko-cluster\"}}"' "<no value>" $((5*minute))
        GEN_CLUSTER_NAME=$(oc get rc "$APP_NAME"-1 --template='{{index .metadata.labels "uses-oshinko-cluster"}}')

    else
	# If the cluster name was not cleared, reuse it
	if [ "$GEN_CLUSTER_NAME" == "" ]; then
            GEN_CLUSTER_NAME=cl-$SUFFIX
	fi
        os::cmd::expect_success 'oc new-app --file="$RESOURCE_DIR"/pysparkdc.json -p IMAGE=play -p OSHINKO_CLUSTER_NAME="$GEN_CLUSTER_NAME" -p APPLICATION_NAME="$APP_NAME" -p APP_EXIT="$DO_EXIT" -p APP_ARGS="$SLEEP" -p OSHINKO_DEL_CLUSTER="$DEL_CLUSTER" -p TEST_MODE="$DO_TEST" -p OSHINKO_NAMED_CONFIG=clusterconfig'
    fi 
    echo Using cluster name $GEN_CLUSTER_NAME
    MASTER_DC=$GEN_CLUSTER_NAME-m
    WORKER_DC=$GEN_CLUSTER_NAME-w
}

function run_job() {
    local pod
    # Launch the app using the service account and create a cluster
    # Until jobs work with image triggers, we need the full pullspec for an image in a job template
    set +e
    SUFFIX=$(cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 4 | head -n 1)
    set -e
    APP_NAME=app-$SUFFIX
    IMAGE_NAME=$(oc get is play --template="{{index .status \"dockerImageRepository\"}}")
    if [ "$#" -ne 1 ]; then
	echo run_job takes 1 parameter, true or false for named or unnamed cluster
	return 1
    fi
    if [ "$1" != true ]; then
        os::cmd::expect_success 'oc new-app --file="$RESOURCE_DIR"/pysparkjob.json -p IMAGE="$IMAGE_NAME" -p APPLICATION_NAME="$APP_NAME" -p APP_EXIT="$DO_EXIT" -p APP_ARGS="$SLEEP" -p OSHINKO_DEL_CLUSTER="$DEL_CLUSTER" -p TEST_MODE="$DO_TEST"'
        # Well, we have no easy way of figuring out what the clustername is here since we're not using a dc but if we figure out the pod name we can grep the log
        # Use the os::cmd_try_until_xxx functions to gate
        os::cmd::try_until_success 'oc get pod -l app="$APP_NAME"'
        pod=$(oc get pod -l app=$APP_NAME --template='{{index .items 0 "metadata" "name"}}')
        os::cmd::try_until_text 'oc logs "$pod"' "Using shared cluster"
        GEN_CLUSTER_NAME=$(oc logs $pod | grep "Using shared cluster" | grep -oE "[^ ]+$")
    else
	# If the cluster name was not cleared, reuse it
	if [ "$GEN_CLUSTER_NAME" == "" ]; then
            GEN_CLUSTER_NAME=cl-$SUFFIX
	fi
        os::cmd::expect_success 'oc new-app --file="$RESOURCE_DIR"/pysparkjob.json -p IMAGE="$IMAGE_NAME" -p OSHINKO_CLUSTER_NAME="$GEN_CLUSTER_NAME" -p APPLICATION_NAME="$APP_NAME" -p APP_EXIT="$DO_EXIT" -p APP_ARGS="$SLEEP" -p OSHINKO_DEL_CLUSTER="$DEL_CLUSTER" -p TEST_MODE="$DO_TEST"'
    fi
    echo Using cluster name $GEN_CLUSTER_NAME
    MASTER_DC=$GEN_CLUSTER_NAME-m
    WORKER_DC=$GEN_CLUSTER_NAME-w
}

function cleanup_app() {

    # We may have code shared by build templates and app templates
    # that calls cleanup_app, and the build tempaltes may not have dcs ...
    set +e
    oc scale dc/"$APP_NAME" --replicas=0 &> /dev/null
    set -e
    os::cmd::try_until_text 'oc get pods -l deploymentconfig="$APP_NAME"' 'No resources found' > /dev/null
    set +e
    oc delete dc/"$APP_NAME" &> /dev/null
    set -e
    if [ "$#" -eq 1 ]; then
        os::cmd::try_until_failure 'oc get dc "$MASTER_DC"' > /dev/null
        os::cmd::try_until_failure 'oc get dc "$WORKER_DC"' > /dev/null
        os::cmd::try_until_failure 'oc get service "$GEN_CLUSTER_NAME"' > /dev/null
        os::cmd::try_until_failure 'oc get service "$GEN_CLUSTER_NAME"-ui' > /dev/null
    fi
}

function cleanup_cluster() {
    # We get tricky here and just use try_until_failure for components that
    # might not actually exist, depending on what we've been doing
    # If present, they'll be deleted and the next call will fail
    os::cmd::try_until_failure 'oc delete service "$GEN_CLUSTER_NAME"-ui' > /dev/null
    os::cmd::try_until_failure 'oc delete service "$GEN_CLUSTER_NAME"' > /dev/null
    os::cmd::try_until_failure 'oc delete dc "$MASTER_DC"' > /dev/null
    os::cmd::try_until_failure 'oc delete dc "$WORKER_DC"' > /dev/null
    if [ "$#" -eq 0 ]; then
        os::cmd::try_until_failure 'oc get service "$GEN_CLUSTER_NAME"' > /dev/null
        os::cmd::try_until_failure 'oc get service "$GEN_CLUSTER_NAME"-ui' > /dev/null
        os::cmd::try_until_failure 'oc get dc "$MASTER_DC"' > /dev/null
        os::cmd::try_until_failure 'oc get dc "$WORKER_DC"' > /dev/null
    fi
} 

function make_image() {
    TEST_IMAGE=play
    set +e
    oc get buildconfig play &> /dev/null
    local res=$?
    set -e
    if [ "$res" -ne 0 ]; then
        # The ip address of the internal registry may be set to support running against
        # an openshift that is not "oc cluster up". In the case of "oc cluster up", the docker
        # on the host is available from openshift so no special pushes of images have to be done.
        # In the case of a "normal" openshift cluster, the image we'll use for build has to be
        # available as an imagestream.
        set +e
        tmp=$(docker history $S2I_TEST_IMAGE_PYSPARK)
        res=$?
        set -e
        if [ "$res" -ne 0 ]; then
            echo Uh oh, image $S2I_TEST_IMAGE_PYSPARK does not exist
            return 1
        fi
        if [ -z "${S2I_TEST_INTEGRATED_REGISTRY}" ]; then
            os::cmd::expect_success 'oc new-build --name=play "$S2I_TEST_IMAGE_PYSPARK" --binary'
        else
            set +e
            docker login --help | grep email &> /dev/null
            res=$?
            set -e
            if [ "$res" -eq 0 ]; then
                docker login -u $(oc whoami) -e jack@jack.com -p $(oc whoami -t) ${S2I_TEST_INTEGRATED_REGISTRY}
            else
                docker login -u $(oc whoami) -p $(oc whoami -t) ${S2I_TEST_INTEGRATED_REGISTRY}
            fi
            docker tag ${S2I_TEST_IMAGE_PYSPARK} ${S2I_TEST_INTEGRATED_REGISTRY}/${PROJECT}/radanalytics-pyspark
            docker push ${S2I_TEST_INTEGRATED_REGISTRY}/${PROJECT}/radanalytics-pyspark
            os::cmd::expect_success 'oc new-build --name=play --image-stream=radanalytics-pyspark --binary'
        fi
    fi
    BUILDNUM=$(oc get buildconfig play --template='{{index .status "lastVersion"}}')
    set +e
    oc get build play-$BUILDNUM &> /dev/null
    res=$?
    set -e
    if [ "$res" -eq 0 ]; then
        # Make sure that the build is complete. If not, start another one.
	phase=$(oc get build play-$BUILDNUM --template="{{index .status \"phase\"}}")
        if [ "$phase" != "Running" -a "$phase" != "Complete" ]; then
            echo "Build phase for play-$BUILDNUM is $phase, restarting..."
            res=1
        fi
    fi
    if [ "$res" -ne 0 ]; then
        os::cmd::expect_success 'oc start-build play --from-file="$RESOURCE_DIR"/play'
        BUILDNUM=$(oc get buildconfig play --template='{{index .status "lastVersion"}}')
        oc logs -f buildconfig/play
    fi
    # Wait for the build to finish
    os::cmd::try_until_text 'oc get build play-"$BUILDNUM" --template="{{index .status \"phase\"}}"' "Complete" $((5*minute))
}
