apiVersion: v1
kind: Template
labels:
  application: oshinko-java-spark
  createdBy: template-oshinko-java-spark-build-dc
metadata:
  annotations:
    description: Create a buildconfig, imagestream and deploymentconfig using source-to-image
      and Java Spark source files hosted in git
    openshift.io/display-name: Apache Spark Java
  creationTimestamp: 2018-03-13T17:12:27Z
  name: oshinko-java-spark-build-dc
  namespace: radanalyticsio
  resourceVersion: "15459931"
  selfLink: /oapi/v1/namespaces/radanalyticsio/templates/oshinko-java-spark-build-dc
  uid: b4953262-26e1-11e8-a70b-246e9602ce14
objects:
- apiVersion: v1
  kind: ImageStream
  metadata:
    name: ${APPLICATION_NAME}
  spec:
    dockerImageRepository: ${APPLICATION_NAME}
    tags:
    - name: latest
- apiVersion: v1
  kind: BuildConfig
  metadata:
    name: ${APPLICATION_NAME}
  spec:
    output:
      to:
        kind: ImageStreamTag
        name: ${APPLICATION_NAME}:latest
    source:
      contextDir: ${CONTEXT_DIR}
      git:
        ref: ${GIT_REF}
        uri: ${GIT_URI}
      type: Git
    strategy:
      sourceStrategy:
        env:
        - name: APP_FILE
          value: ${APP_FILE}
        forcePull: true
        from:
          kind: DockerImage
          name: rimolive/radanalytics-java-spark
      type: Source
    triggers:
    - imageChange: {}
      type: ImageChange
    - type: ConfigChange
    - github:
        secret: ${APPLICATION_NAME}
      type: GitHub
    - generic:
        secret: ${APPLICATION_NAME}
      type: Generic
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    labels:
      deploymentConfig: ${APPLICATION_NAME}
    name: ${APPLICATION_NAME}
  spec:
    replicas: 1
    selector:
      deploymentConfig: ${APPLICATION_NAME}
    strategy:
      type: Rolling
    template:
      metadata:
        labels:
          deploymentConfig: ${APPLICATION_NAME}
      spec:
        containers:
        - env:
          - name: APPLICATION_NAME
            value: ${APPLICATION_NAME}
          - name: OSHINKO_CLUSTER_NAME
            value: ${OSHINKO_CLUSTER_NAME}
          - name: APP_ARGS
            value: ${APP_ARGS}
          - name: SPARK_OPTIONS
            value: ${SPARK_OPTIONS}
          - name: APP_MAIN_CLASS
            value: ${APP_MAIN_CLASS}
          - name: OSHINKO_DEL_CLUSTER
            value: ${OSHINKO_DEL_CLUSTER}
          - name: OSHINKO_KUBE_SCHEDULER
            value: ${OSHINKO_KUBE_SCHEDULER}
          - name: APP_EXIT
            value: ${APP_EXIT}
          - name: OSHINKO_NAMED_CONFIG
            value: ${OSHINKO_NAMED_CONFIG}
          - name: OSHINKO_SPARK_DRIVER_CONFIG
            value: ${OSHINKO_SPARK_DRIVER_CONFIG}
          - name: DOCKER_REGISTRY_LOCATION
            value: ${DOCKER_REGISTRY_LOCATION}
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          image: ${APPLICATION_NAME}
          imagePullPolicy: IfNotPresent
          name: ${APPLICATION_NAME}
          resources: {}
          terminationMessagePath: /dev/termination-log
          volumeMounts:
          - mountPath: /etc/podinfo
            name: podinfo
            readOnly: false
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        serviceAccount: oshinko
        volumes:
        - downwardAPI:
            items:
            - fieldRef:
                fieldPath: metadata.labels
              path: labels
          name: podinfo
    triggers:
    - imageChangeParams:
        automatic: true
        containerNames:
        - ${APPLICATION_NAME}
        from:
          kind: ImageStreamTag
          name: ${APPLICATION_NAME}:latest
      type: ImageChange
    - type: ConfigChange
- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}
  spec:
    ports:
    - name: 8080-tcp
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      deploymentConfig: ${APPLICATION_NAME}
parameters:
- description: The name to use for the buildconfig, imagestream and deployment objects
  from: java-spark-[a-z0-9]{4}
  generate: expression
  name: APPLICATION_NAME
  required: true
- description: Git source URI for application
  name: GIT_URI
- description: Git branch/tag reference
  name: GIT_REF
  value: master
- description: Git sub-directory path
  name: CONTEXT_DIR
- description: The name of the main JAR file. If this is not specified and there is
    a single JAR produced by the build, that JAR will be chosen.
  name: APP_FILE
- description: Command line arguments to pass to the Spark application
  name: APP_ARGS
- description: Application main class for jar-based applications
  name: APP_MAIN_CLASS
- description: List of additional Spark options to pass to spark-submit (for example
    --conf property=value --conf property=value). Note, --master and --class are set
    by the launcher and should not be set here
  name: SPARK_OPTIONS
- description: Choose whether to use native k8s Scheduler or Spark Standalone
  name: OSHINKO_KUBE_SCHEDULER
  required: true
  value: "false"
- description: In case of using k8s scheduler, it is required to provide the registry location so S2i can find the Driver image.
  name: DOCKER_REGISTRY_LOCATION
  value: "docker-registry.default.svc:5000"
- description: The name of the Spark cluster to run against. The cluster will be created
    if it does not exist, and a random cluster name will be chosen if this value is
    left blank.
  name: OSHINKO_CLUSTER_NAME
- description: The name of a stored cluster configuration to use if a cluster is created,
    default is 'default'.
  name: OSHINKO_NAMED_CONFIG
- description: The name of a configmap to use for the Spark configuration of the driver.
    If this configmap is empty the default Spark configuration will be used.
  name: OSHINKO_SPARK_DRIVER_CONFIG
- description: If a cluster is created on-demand, delete the cluster when the application
    finishes if this option is set to 'true'
  name: OSHINKO_DEL_CLUSTER
  required: true
  value: "true"
- description: Setting this value to 'false' prevents the application from being re-deployed
    if/when it completes
  name: APP_EXIT
  required: true
  value: "false"
